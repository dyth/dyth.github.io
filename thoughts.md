These thoughts may eventually form a blog, but I have no time to do that yet

## It's unclear what AI means
1. Anthropomorphising machines and saying that they have human qualities (intelligence, learning) may not necessarily help us develop more powerful machines.
2. If anthropomorphised, a defective machine's creator may deflect blame from themselves and towards the machine, claiming that it has some subjective bias.
3. We do not know enough about learning/intelligence to say that our machines have/are doing either.
4. Society does not need more voices/actors/"intelligences"
